{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "#pip install pytorch(online download)\n",
    "#pip install easyocr     for the image to be converted to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import easyocr\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds image processing capabilities\n",
    "from PIL import Image\n",
    "# will convert the image to text string\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authenticate use of ibm text characters \n",
    "url = 'https://api.au-syd.text-to-speech.watson.cloud.ibm.com/instances/2996ca49-c504-46aa-a871-4f9d74575923'\n",
    "apikey = 'hsnvQiGddoZ-16sON0lrf5uhdZw6x4Uf1S97DL6KzqJ9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import TextToSpeechV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image or video\n",
    "IMAGE_PATH = 'E:/Skills/Languages/A PROJECTS/Image To Speech/Image1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Unknown C++ exception from OpenCV code",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# #optical caracter recognition\u001b[39;00m\n\u001b[0;32m      2\u001b[0m reader \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mReader([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m], gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m result\n",
      "File \u001b[1;32mD:\\Python\\lib\\site-packages\\easyocr\\easyocr.py:385\u001b[0m, in \u001b[0;36mReader.readtext\u001b[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, output_format)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mimage: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    383\u001b[0m img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(image)\n\u001b[1;32m--> 385\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[0;32m    392\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\Python\\lib\\site-packages\\easyocr\\easyocr.py:275\u001b[0m, in \u001b[0;36mReader.detect\u001b[1;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reformat:\n\u001b[0;32m    273\u001b[0m     img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(img)\n\u001b[1;32m--> 275\u001b[0m text_box_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_textbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m horizontal_list_agg, free_list_agg \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_box \u001b[38;5;129;01min\u001b[39;00m text_box_list:\n",
      "File \u001b[1;32mD:\\Python\\lib\\site-packages\\easyocr\\detection.py:95\u001b[0m, in \u001b[0;36mget_textbox\u001b[1;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars)\u001b[0m\n\u001b[0;32m     93\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     94\u001b[0m estimate_num_chars \u001b[38;5;241m=\u001b[39m optimal_num_chars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m bboxes_list, polys_list \u001b[38;5;241m=\u001b[39m \u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimate_num_chars:\n\u001b[0;32m    100\u001b[0m     polys_list \u001b[38;5;241m=\u001b[39m [[p \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(polys, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mabs\u001b[39m(optimal_num_chars \u001b[38;5;241m-\u001b[39m x[\u001b[38;5;241m1\u001b[39m]))]\n\u001b[0;32m    101\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m polys \u001b[38;5;129;01min\u001b[39;00m polys_list]\n",
      "File \u001b[1;32mD:\\Python\\lib\\site-packages\\easyocr\\detection.py:55\u001b[0m, in \u001b[0;36mtest_net\u001b[1;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[0;32m     52\u001b[0m score_link \u001b[38;5;241m=\u001b[39m out[:, :, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Post-processing\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m boxes, polys, mapper \u001b[38;5;241m=\u001b[39m \u001b[43mgetDetBoxes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscore_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# coordinate adjustment\u001b[39;00m\n\u001b[0;32m     59\u001b[0m boxes \u001b[38;5;241m=\u001b[39m adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
      "File \u001b[1;32mD:\\Python\\lib\\site-packages\\easyocr\\craft_utils.py:236\u001b[0m, in \u001b[0;36mgetDetBoxes\u001b[1;34m(textmap, linkmap, text_threshold, link_threshold, low_text, poly, estimate_num_chars)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m poly \u001b[38;5;129;01mand\u001b[39;00m estimate_num_chars:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimating the number of characters not currently supported with poly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 236\u001b[0m boxes, labels, mapper \u001b[38;5;241m=\u001b[39m \u001b[43mgetDetBoxes_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtextmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinkmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m poly:\n\u001b[0;32m    239\u001b[0m     polys \u001b[38;5;241m=\u001b[39m getPoly_core(boxes, labels, mapper, linkmap)\n",
      "File \u001b[1;32mD:\\Python\\lib\\site-packages\\easyocr\\craft_utils.py:31\u001b[0m, in \u001b[0;36mgetDetBoxes_core\u001b[1;34m(textmap, linkmap, text_threshold, link_threshold, low_text, estimate_num_chars)\u001b[0m\n\u001b[0;32m     28\u001b[0m ret, link_score \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(linkmap, link_threshold, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m text_score_comb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(text_score \u001b[38;5;241m+\u001b[39m link_score, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m nLabels, labels, stats, centroids \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectedComponentsWithStats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_score_comb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnectivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m det \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     34\u001b[0m mapper \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: Unknown C++ exception from OpenCV code"
     ]
    }
   ],
   "source": [
    "\n",
    "# #optical caracter recognition\n",
    "reader = easyocr.Reader(['en'], gpu=False)\n",
    "result = reader.readtext(IMAGE_PATH)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw result \n",
    "top_left = tuple(result[0][0][0])\n",
    "bottom_right = tuple(result[0][0][2])\n",
    "text = result[0][1]\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "img = cv2.putText(img, text, top_left, font, .5, (255,255,255),2,cv2.LINE_AA)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where the tesseract module is installed\n",
    "pytesseract.pytesseract.tesseract_cmd ='C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "# converts the image to result and saves it into result variable\n",
    "result = pytesseract.image_to_string(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_result.txt', mode ='w') as file:\n",
    " file.write(result)\n",
    " print(\"ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup service\n",
    "authenticator = IAMAuthenticator(apikey)\n",
    "\n",
    "#new TTS Service\n",
    "tts = TextToSpeechV1(authenticator=authenticator)\n",
    "\n",
    "#set Service URL\n",
    "tts.set_service_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert form  a file \n",
    "with open ('text_result.txt', 'r') as f:\n",
    "    text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (line.replace('\\n', ' ') for line in text)\n",
    "text = ''.join(str(line) for line in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to string\n",
    "with open ('./speech.mp3','wb') as audio_file:\n",
    "    res = tts.synthesize(text,accept='audio/mp3' , voice='en-US_AllisonV3Voice').get_result()\n",
    "    audio_file.write(res.content)\n",
    "print(\"ready\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
